Week 10: PySpark Data Processing

Requirements
* Use PySpark to perform data processing on a large dataset
* Include at least one Spark SQL query and one data transformation
  
Grading Criteria
* Data processing functionality (20 points)
* Use of Spark SQL and transformations (20 points)
  
Deliverables
* PySpark script
part 1: intializing pyspark:
![int](https://github.com/dumeixiang/mini10-mx/blob/main/Screen%20Shot%202023-11-05%20at%2010.02.16%20PM.png)

part 2:read csv in pyspark sql:
![read](https://github.com/dumeixiang/mini10-mx/blob/main/Screen%20Shot%202023-11-05%20at%2010.02.25%20PM.png)

part 3transfor data and create new column "ifchild":
![transfirm](https://github.com/dumeixiang/mini10-mx/blob/main/Screen%20Shot%202023-11-05%20at%2010.02.30%20PM.png)

* Output data or summary report (PDF or markdown)

Par 1ï¼› original output:
![read_csv](https://github.com/dumeixiang/mini10-mx/blob/main/Screen%20Shot%202023-11-05%20at%2010.38.47%20PM.png)
![spark_csv](https://github.com/dumeixiang/mini10-mx/blob/main/Screen%20Shot%202023-11-05%20at%2010.39.28%20PM.png)
